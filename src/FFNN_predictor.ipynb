{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import Lasso, LassoCV, LogisticRegressionCV, LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, explained_variance_score, normalized_mutual_info_score, mutual_info_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "# from keras.layers import Lambda\n",
    "\n",
    "from hyperopt import Trials, fmin, tpe, hp, STATUS_OK\n",
    "\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.data import iris_data\n",
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle as pkl\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom model implementations and functions are stored in `src/dairyml.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dairyml import PerfectClassifierMeanRegressor, plot_r2, BoundedLasso, BoundedLassoPlusLogReg, plot_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data\n",
    "Load the data from the pickle files created in `preproccess.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../pkl/data/data_outliers_removed\", \"rb\" ) as f:\n",
    "    [X, Y] = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Feed-Forward Neural Network (FFNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the below splitter for cross-validation: 10 folds, with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter= KFold(n_splits=5,shuffle=True,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define r^2 metric for keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_layers,num_nodes,alpha=0.01,lr=.001): \n",
    "    \n",
    "    reg = regularizers.l2(alpha)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(num_nodes, input_dim=X.shape[1], activation='relu', kernel_regularizer = reg))\n",
    "    \n",
    "    for i in range(0,hidden_layers-1):\n",
    "        model.add(Dense(num_nodes, activation='relu', kernel_regularizer = reg))\n",
    "        \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    \n",
    "    #add r2 and other metrics\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam,metrics=['mean_absolute_error',r2_keras])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use r2 scoring in cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'r2':make_scorer(r2_score), \n",
    "           'SRC':make_scorer(spearman), \n",
    "           'PCC':make_scorer(pearson), \n",
    "           'MI':make_scorer(mutual_info_score), \n",
    "           'MAE':make_scorer(mean_absolute_error)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    overall_results = pd.read_csv('../reports/model_results.csv',index_col=0)\n",
    "except FileNotFoundError:\n",
    "    overall_results = pd.DataFrame(columns = scoring.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curves for train test split to estimate appropriate number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(1,60)\n",
    "\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=7, shuffle=True)\n",
    "# # plot_learning_curves(X_train, y_train, X_test, y_test, model, scoring='r2')\n",
    "\n",
    "# X_shuf, Y_shuf = shuffle(X,Y,random_state=7)\n",
    "\n",
    "\n",
    "# history = model.fit(X_shuf, Y_shuf, validation_split=0.2, epochs=200, batch_size=10, verbose=0)\n",
    "# # list all data in history\n",
    "# print(history.history.keys())\n",
    "\n",
    "\n",
    "# plt.plot(history.history['r2_keras'])\n",
    "# plt.plot(history.history['val_r2_keras'])\n",
    "# plt.title('R2')\n",
    "# plt.ylabel('R2')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.ylim(0,1)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objective function (1-r2) for hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "def objective(params):\n",
    "    hidden_layers = int(params['hidden_layers'])\n",
    "    num_nodes = int(params['num_nodes'])\n",
    "    alpha = params['alpha']\n",
    "    lr = params['lr']\n",
    "    \n",
    "    # Print configuration\n",
    "    print('hidden_layers: {}'.format(hidden_layers))\n",
    "    print('num_nodes: {}'.format(num_nodes))\n",
    "    print('alpha: {}'.format(alpha))\n",
    "    print('lr: {}'.format(lr))\n",
    "    \n",
    "    # build keras model with given configuration\n",
    "    model = KerasRegressor(build_fn=create_model,\n",
    "                           hidden_layers=hidden_layers,\n",
    "                           num_nodes=num_nodes,\n",
    "                           alpha=alpha,\n",
    "                           lr=lr,\n",
    "                           epochs=EPOCHS, \n",
    "                           batch_size=5, \n",
    "                           verbose=0)\n",
    "    # get cv results\n",
    "    results = cross_validate(model,X,Y,cv=splitter,scoring=scoring)\n",
    "    \n",
    "    # get average r2 from cv\n",
    "    r2 = np.mean(results['test_r2'])\n",
    "    \n",
    "    # convert r2 to a loss\n",
    "    loss = 1 - r2\n",
    "    \n",
    "    # print r2 result\n",
    "    print('R^2: {}'.format(r2))\n",
    "    print('\\n')\n",
    "    \n",
    "    # return loss\n",
    "    return {'loss': loss, 'params': params, 'cv_results': results, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min, max, stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "            'hidden_layers': hp.quniform('hidden_layers', 1, 2, 1),\n",
    "            'num_nodes': hp.qloguniform('num_nodes', np.log(3), np.log(100), 1),\n",
    "            'lr': hp.loguniform('lr', np.log(1e-4), np.log(1e-2)),\n",
    "            'alpha': hp.loguniform('alpha', np.log(1e-4), np.log(1e-1))\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trials object to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layers: 1\n",
      "num_nodes: 3\n",
      "alpha: 0.011919348950814248\n",
      "lr: 0.008696534757119328\n",
      "R^2: 0.5416689502982143\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 3\n",
      "alpha: 0.00020897271956071595\n",
      "lr: 0.0008356388496771893\n",
      "R^2: 0.6244959023328084\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 40\n",
      "alpha: 0.014550696296277088\n",
      "lr: 0.0013488799122571282\n",
      "R^2: 0.6273493122402498\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 15\n",
      "alpha: 0.00016259008566805636\n",
      "lr: 0.00303136585715929\n",
      "R^2: 0.670933823242754\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 14\n",
      "alpha: 0.08507975722250913\n",
      "lr: 0.0003230701818184669\n",
      "R^2: 0.5537815767459113\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 11\n",
      "alpha: 0.0038428763695687565\n",
      "lr: 0.0002261146652768974\n",
      "R^2: 0.6666974220239805\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 69\n",
      "alpha: 0.001217427134968658\n",
      "lr: 0.0006437673256730367\n",
      "R^2: 0.6891895200319381\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 17\n",
      "alpha: 0.027634252171355827\n",
      "lr: 0.009623762199187966\n",
      "R^2: 0.6086432254029224\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 45\n",
      "alpha: 0.04684415929397044\n",
      "lr: 0.002343926589674816\n",
      "R^2: 0.658396081868497\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 4\n",
      "alpha: 0.0009037362320658456\n",
      "lr: 0.003490570362723046\n",
      "R^2: 0.6261539713311722\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 24\n",
      "alpha: 0.00036228071739875854\n",
      "lr: 0.008996709792855263\n",
      "R^2: 0.6595198252627089\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 75\n",
      "alpha: 0.003130244418949534\n",
      "lr: 0.0038865553107021874\n",
      "R^2: 0.6637123853501847\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 14\n",
      "alpha: 0.00010964009067260052\n",
      "lr: 0.0005641419746899879\n",
      "R^2: 0.5887981582710502\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 15\n",
      "alpha: 0.04360663981037773\n",
      "lr: 0.0003404795247354206\n",
      "R^2: 0.5838071416259666\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 11\n",
      "alpha: 0.0005805640048884873\n",
      "lr: 0.00029618807872804705\n",
      "R^2: 0.5144688016978247\n",
      "\n",
      "\n",
      "hidden_layers: 2\n",
      "num_nodes: 96\n",
      "alpha: 0.00011578005037215803\n",
      "lr: 0.0002600120961919376\n",
      "R^2: 0.6440216161681944\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 88\n",
      "alpha: 0.012188239570492044\n",
      "lr: 0.00035959179115242616\n",
      "R^2: 0.6306748615355828\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 59\n",
      "alpha: 0.005660851233300683\n",
      "lr: 0.001994170783323986\n",
      "R^2: 0.7100208234567651\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 21\n",
      "alpha: 0.00013430325642101014\n",
      "lr: 0.0010632582239894464\n",
      "R^2: 0.6371319201249882\n",
      "\n",
      "\n",
      "hidden_layers: 1\n",
      "num_nodes: 4\n",
      "alpha: 0.0012023161709806343\n",
      "lr: 0.00584694848625239\n",
      "R^2: 0.5611402516043767\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_EVALS = 20\n",
    "\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(params):\n",
    "    save_string = 'FFNN_best_params-' + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M %p\"))\n",
    "    params_dir = \"../pkl/params/FFNN/\"\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(params_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    with open(params_dir + save_string, \"wb\" ) as f:\n",
    "        f.seek(0)\n",
    "        pkl.dump(params,f)\n",
    "\n",
    "def load_params():\n",
    "    params_dir = \"../pkl/params/FFNN/*\"\n",
    "    list_of_files = glob.glob(params_dir)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print('loading {}'.format(latest_file))\n",
    "    \n",
    "    with open(latest_file, \"rb\") as f:\n",
    "        f.seek(0)\n",
    "        params = pkl.load(f)\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trials(trials):\n",
    "    save_string = 'FFNN_trials-' + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M %p\"))\n",
    "    trials_dir = '../pkl/trials/FFNN/'\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(trials_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    with open(trials_dir + save_string, \"wb\" ) as f:\n",
    "        f.seek(0)\n",
    "        pkl.dump(trials,f)\n",
    "        \n",
    "    print('saved to {}'.format(trials_dir + save_string))\n",
    "\n",
    "def load_trials():\n",
    "    trials_dir = \"../pkl/trials/FFNN/*\"\n",
    "    list_of_files = glob.glob(trials_dir)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print('loading {}'.format(latest_file))\n",
    "    \n",
    "    with open(latest_file, \"rb\") as f:\n",
    "        f.seek(0)\n",
    "        trials = pkl.load(f)\n",
    "        \n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../pkl/params/FFNN\\FFNN_best_params-2019-01-21 12-43 PM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.005660851233300683,\n",
       " 'hidden_layers': 1.0,\n",
       " 'lr': 0.001994170783323986,\n",
       " 'num_nodes': 59.0}"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_params(best)\n",
    "load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ../pkl/trials/FFNN/FFNN_trials-2019-01-21 12-44 PM\n",
      "loading ../pkl/trials/FFNN\\FFNN_trials-2019-01-21 12-44 PM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hyperopt.base.Trials at 0xb992c240>"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_trials(trials)\n",
    "load_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trials so far were conducted with only r2 in the scoring dict, so I added the other metrics then re-ran with what was supposedly the best configuration. This achieved .71 r^2 above, but only .65 below. This is not very consistent at all, maybe need to increase the number of folds in CV, or increase number of epochs. Also thinking about setting number of epochs much higher and just using early stopping to get to the appropriate number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layers: 1\n",
      "num_nodes: 59\n",
      "alpha: 0.005660851233300683\n",
      "lr: 0.001994170783323986\n",
      "R^2: 0.655077183043743\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final_model_results = objective(trials.best_trial['result']['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>SRC</th>\n",
       "      <th>PCC</th>\n",
       "      <th>MI</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Mean</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Median All</th>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Median Nonzero</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perfect Clasif., Mean Regr.</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.07</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bounded Lasso</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bounded Lasso + LogReg</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFNN</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               r2   SRC   PCC    MI   MAE\n",
       "Dummy Mean                  -0.02  0.00 -0.00 -0.00  1.94\n",
       "Dummy Median All            -0.32  0.00 -0.00 -0.00  1.68\n",
       "Dummy Median Nonzero        -0.08  0.00 -0.00 -0.00  1.77\n",
       "Perfect Clasif., Mean Regr.  0.13  0.73  0.41  0.53  1.53\n",
       "Lasso                        0.45  0.61  0.70  3.07  1.23\n",
       "Bounded Lasso                0.55  0.64  0.75  2.87  1.08\n",
       "Bounded Lasso + LogReg       0.64  0.80  0.82  2.66  0.86\n",
       "FFNN                         0.66  0.70  0.83  3.58  0.96"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for score_name in scoring.keys():\n",
    "    overall_results.loc['FFNN',score_name] = np.round(np.mean(final_model_results['cv_results']['test_'+score_name]),2)\n",
    "overall_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results.to_csv('../reports/model_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
