{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, cross_validate\n",
    "from sklearn.metrics import r2_score, \\\n",
    "    explained_variance_score, normalized_mutual_info_score, mutual_info_score, make_scorer, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skll.metrics import spearman, pearson\n",
    "\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from hyperopt import Trials, fmin, tpe, hp, STATUS_OK\n",
    "\n",
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom model implementations and functions are stored in `src/dairyml.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dairyml import PerfectClassifierMeanRegressor, plot_r2, plot_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data\n",
    "Load the data from the pickle files created in `preproccess.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../pkl/data/data_outliers_removed\", \"rb\" ) as f:\n",
    "    [X, Y] = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Feed-Forward Neural Network (FFNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently using 5 folds to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter= KFold(n_splits=5,shuffle=True,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define r^2 metric for keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_layers,num_nodes,alpha=0.01,lr=.001): \n",
    "    \n",
    "    reg = regularizers.l2(alpha)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(num_nodes, input_dim=X.shape[1], activation='relu', kernel_regularizer = reg))\n",
    "    \n",
    "    for i in range(0,hidden_layers-1):\n",
    "        model.add(Dense(num_nodes, activation='relu', kernel_regularizer = reg))\n",
    "        \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    \n",
    "    #add r2 and other metrics\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam,metrics=['mean_absolute_error',r2_keras])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use r2 scoring in cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'r2':make_scorer(r2_score), \n",
    "           'SRC':make_scorer(spearman), \n",
    "           'PCC':make_scorer(pearson), \n",
    "           'MI':make_scorer(mutual_info_score), \n",
    "           'MAE':make_scorer(mean_absolute_error)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    overall_results = pd.read_csv('../reports/model_results.csv',index_col=0)\n",
    "except FileNotFoundError:\n",
    "    overall_results = pd.DataFrame(columns = scoring.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curves for train test split to estimate appropriate number of epochs\n",
    "Can replace this with just early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objective function (1-r2) for hyperopt\n",
    "\n",
    "need to print more information here:\n",
    "  - early stopping status for each split of cv\n",
    "  - scores for each part of cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 2000\n",
    "# X_shuf, Y_shuf = shuffle(X,Y,random_state=7)\n",
    "\n",
    "def objective(params):\n",
    "    hidden_layers = int(params['hidden_layers'])\n",
    "    num_nodes = int(params['num_nodes'])\n",
    "    alpha = params['alpha']\n",
    "    lr = params['lr']\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    # Print configuration\n",
    "    print('hidden_layers: {}'.format(hidden_layers))\n",
    "    print('num_nodes: {}'.format(num_nodes))\n",
    "    print('alpha: {}'.format(alpha))\n",
    "    print('lr: {}'.format(lr))\n",
    "    print('epochs: {}'.format(epochs))\n",
    "    \n",
    "    # build keras model with given configuration\n",
    "    model = KerasRegressor(build_fn=create_model,\n",
    "                           hidden_layers=hidden_layers,\n",
    "                           num_nodes=num_nodes,\n",
    "                           alpha=alpha,\n",
    "                           lr=lr,\n",
    "                           epochs=epochs, \n",
    "                           verbose=0)\n",
    "    # get cv results\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=20,mode='min',verbose=1)\n",
    "    results = cross_validate(model,X,Y,cv=splitter,scoring=scoring)\n",
    "#     history = model.fit(X_shuf,Y_shuf,validation_split=0.2,callbacks=[early_stopping],epochs = EPOCHS)\n",
    "    \n",
    "#     print('early stopping: {}'.format(early_stopping.stopped_epoch))\n",
    "    # get average r2 from cv\n",
    "    r2 = np.mean(results['test_r2'])\n",
    "    \n",
    "#     r2 = history.history['val_r2_keras'][-1]\n",
    "    \n",
    "    # convert r2 to a loss\n",
    "    loss = 1 - r2\n",
    "    \n",
    "    # print r2 result\n",
    "    print('R^2: {}'.format(r2))\n",
    "    print('\\n')\n",
    "    \n",
    "    # return loss\n",
    "    return {'loss': loss, 'params': params, 'r2': r2, 'cv_results': results, 'status': STATUS_OK}\n",
    "#     return {'loss': loss, 'params': params, 'early_stopping': early_stopping.stopped_epoch, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min, max, stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "            'hidden_layers': hp.quniform('hidden_layers', 1, 2, 1),\n",
    "            'num_nodes': hp.qloguniform('num_nodes', np.log(3), np.log(100), 1),\n",
    "            'lr': hp.loguniform('lr', np.log(1e-4), np.log(1e-2)),\n",
    "            'alpha': hp.loguniform('alpha', np.log(1e-4), np.log(1e-1)),\n",
    "            'epochs': hp.qnormal('epochs',150,25,5)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trials object to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperopt\n",
    "\n",
    "### need to print early stopping for each iter of cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_EVALS = 100\n",
    "# # Optimize\n",
    "# best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials():\n",
    "\n",
    "    trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 3  # initial max_trials. put something small to not have to wait\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = load_trials()\n",
    "#         trials = Trials()\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "    print(\"Best:\", best)\n",
    "    \n",
    "    # save the trials object\n",
    "    save_trials(trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    run_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000\n",
    "\n",
    "def create_from_params(params):\n",
    "    hidden_layers = int(params['hidden_layers'])\n",
    "    num_nodes = int(params['num_nodes'])\n",
    "    alpha = params['alpha']\n",
    "    lr = params['lr']\n",
    "    \n",
    "    model = KerasRegressor(build_fn=create_model,\n",
    "                       hidden_layers=hidden_layers,\n",
    "                       num_nodes=num_nodes,\n",
    "                       alpha=alpha,\n",
    "                       lr=lr,\n",
    "                       epochs=120, \n",
    "                       verbose=0)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_from_params(best)\n",
    "\n",
    "results = cross_validate(model,X,Y,cv=splitter,scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584380188790888"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.mean(results['test_r2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(params):\n",
    "    save_string = 'FFNN_best_params-' + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M %p\"))\n",
    "    params_dir = \"../pkl/params/FFNN/\"\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(params_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    with open(params_dir + save_string, \"wb\" ) as f:\n",
    "        f.seek(0)\n",
    "        pkl.dump(params,f)\n",
    "\n",
    "def load_params():\n",
    "    params_dir = \"../pkl/params/FFNN/*\"\n",
    "    list_of_files = glob.glob(params_dir)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print('loading {}'.format(latest_file))\n",
    "    \n",
    "    with open(latest_file, \"rb\") as f:\n",
    "        f.seek(0)\n",
    "        params = pkl.load(f)\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trials(trials):\n",
    "    save_string = 'FFNN_trials-' + str(datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M %p\"))\n",
    "    trials_dir = '../pkl/trials/FFNN/'\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(trials_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    with open(trials_dir + save_string, \"wb\" ) as f:\n",
    "        f.seek(0)\n",
    "        pkl.dump(trials,f)\n",
    "        \n",
    "    print('saved to {}'.format(trials_dir + save_string))\n",
    "\n",
    "def load_trials():\n",
    "    trials_dir = \"../pkl/trials/FFNN/*\"\n",
    "    list_of_files = glob.glob(trials_dir)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print('loading {}'.format(latest_file))\n",
    "    \n",
    "    with open(latest_file, \"rb\") as f:\n",
    "        f.seek(0)\n",
    "        trials = pkl.load(f)\n",
    "        \n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../pkl/params/FFNN\\FFNN_best_params-2019-01-21 12-43 PM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.005660851233300683,\n",
       " 'hidden_layers': 1.0,\n",
       " 'lr': 0.001994170783323986,\n",
       " 'num_nodes': 59.0}"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_params(best)\n",
    "load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ../pkl/trials/FFNN/FFNN_trials-2019-01-24 04-02 AM\n"
     ]
    }
   ],
   "source": [
    "save_trials(trials)\n",
    "# load_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trials so far were conducted with only r2 in the scoring dict, so I added the other metrics then re-ran with what was supposedly the best configuration. This achieved .71 r^2 above, but only .65 below. This is not very consistent at all, maybe need to increase the number of folds in CV, or increase number of epochs. Also thinking about setting number of epochs much higher and just using early stopping to get to the appropriate number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layers: 1\n",
      "num_nodes: 59\n",
      "alpha: 0.005660851233300683\n",
      "lr: 0.001994170783323986\n",
      "R^2: 0.655077183043743\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final_model_results = objective(trials.best_trial['result']['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>SRC</th>\n",
       "      <th>PCC</th>\n",
       "      <th>MI</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Mean</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Median All</th>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Median Nonzero</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perfect Clasif., Mean Regr.</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.07</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bounded Lasso</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bounded Lasso + LogReg</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFNN</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               r2   SRC   PCC    MI   MAE\n",
       "Dummy Mean                  -0.02  0.00 -0.00 -0.00  1.94\n",
       "Dummy Median All            -0.32  0.00 -0.00 -0.00  1.68\n",
       "Dummy Median Nonzero        -0.08  0.00 -0.00 -0.00  1.77\n",
       "Perfect Clasif., Mean Regr.  0.13  0.73  0.41  0.53  1.53\n",
       "Lasso                        0.45  0.61  0.70  3.07  1.23\n",
       "Bounded Lasso                0.55  0.64  0.75  2.87  1.08\n",
       "Bounded Lasso + LogReg       0.64  0.80  0.82  2.66  0.86\n",
       "FFNN                         0.66  0.70  0.83  3.58  0.96"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for score_name in scoring.keys():\n",
    "    overall_results.loc['FFNN',score_name] = np.round(np.mean(final_model_results['cv_results']['test_'+score_name]),2)\n",
    "overall_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results.to_csv('../reports/model_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
